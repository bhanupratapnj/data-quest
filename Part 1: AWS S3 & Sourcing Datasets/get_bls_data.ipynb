{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d68b7a73-b24e-41f8-8dee-d64d367cff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<bound method Response.json of <Response [200]>>\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "AWS_S3_NAME = \"rearc-dataquest-s3bucket\"\n",
    "BLS_DATA = \"https://download.bls.gov/pub/time.series/pr/\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"rearc/1.0 (bhanu.tcs@gmail.com)\"\n",
    "}\n",
    "response = requests.get(BLS_DATA, headers=headers)\n",
    "print(response)\n",
    "print(response.json)\n",
    "\n",
    "## To initialize S3 resource and refer the specific bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(AWS_S3_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "261e3c46-6917-4af7-bb30-03b99b32732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.Bucket(name='rearc-dataquest-s3bucket')\n"
     ]
    }
   ],
   "source": [
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba101431-5efb-4613-a534-8254102d1e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pr.class', 'pr.contacts', 'pr.data.0.Current', 'pr.data.1.AllData', 'pr.duration', 'pr.footnote', 'pr.measure', 'pr.period', 'pr.seasonal', 'pr.sector', 'pr.series', 'pr.txt']\n"
     ]
    }
   ],
   "source": [
    "# Get bucket contents\n",
    "bucket_objects = []\n",
    "for obj in bucket.objects.all():\n",
    "    bucket_objects.append(obj.key)\n",
    "print(bucket_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95f7b6ae-05b2-4407-87f4-626289e9147e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pr.class', 'pr.contacts', 'pr.data.0.Current', 'pr.data.1.AllData', 'pr.duration', 'pr.footnote', 'pr.measure', 'pr.period', 'pr.seasonal', 'pr.sector', 'pr.series', 'pr.txt']\n"
     ]
    }
   ],
   "source": [
    "# Track files that don't exist on the website\n",
    "deleted_list = bucket_objects.copy()\n",
    "print(deleted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adc2adea-99ae-4ff0-9d32-c224cb543431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head><title>download.bls.gov - /pub/time.series/pr/</title></head><body><h1>download.bls.gov - /pub/time.series/pr/</h1><hr/>\n",
      "<pre><a href=\"/pub/time.series/\">[To Parent Directory]</a><br/><br/>  9/4/2025  8:30 AM          102 <a href=\"/pub/time.series/pr/pr.class\">pr.class</a><br/> 9/13/2022  4:52 PM          562 <a href=\"/pub/time.series/pr/pr.contacts\">pr.contacts</a><br/>  9/4/2025  8:30 AM      1564284 <a href=\"/pub/time.series/pr/pr.data.0.Current\">pr.data.0.Current</a><br/>  9/4/2025  8:30 AM      3187878 <a href=\"/pub/time.series/pr/pr.data.1.AllData\">pr.data.1.AllData</a><br/>  9/4/2025  8:30 AM          176 <a href=\"/pub/time.series/pr/pr.duration\">pr.duration</a><br/>  9/4/2025  8:30 AM           40 <a href=\"/pub/time.series/pr/pr.footnote\">pr.footnote</a><br/>  9/4/2025  8:30 AM          745 <a href=\"/pub/time.series/pr/pr.measure\">pr.measure</a><br/>  1/7/1994  3:53 PM          146 <a href=\"/pub/time.series/pr/pr.period\">pr.period</a><br/>11/18/2011  4:05 PM           79 <a href=\"/pub/time.series/pr/pr.seasonal\">pr.seasonal</a><br/>  9/4/2025  8:30 AM          263 <a href=\"/pub/time.series/pr/pr.sector\">pr.sector</a><br/>  9/4/2025  8:30 AM        15657 <a href=\"/pub/time.series/pr/pr.series\">pr.series</a><br/>11/17/2011  5:11 PM        18343 <a href=\"/pub/time.series/pr/pr.txt\">pr.txt</a><br/></pre><hr/></body></html>\n",
      "['pr.contacts', 'pr.data.0.Current', 'pr.data.1.AllData', 'pr.duration', 'pr.footnote', 'pr.measure', 'pr.period', 'pr.seasonal', 'pr.sector', 'pr.series', 'pr.txt']\n",
      "['pr.data.0.Current', 'pr.data.1.AllData', 'pr.duration', 'pr.footnote', 'pr.measure', 'pr.period', 'pr.seasonal', 'pr.sector', 'pr.series', 'pr.txt']\n",
      "['pr.data.1.AllData', 'pr.duration', 'pr.footnote', 'pr.measure', 'pr.period', 'pr.seasonal', 'pr.sector', 'pr.series', 'pr.txt']\n",
      "['pr.duration', 'pr.footnote', 'pr.measure', 'pr.period', 'pr.seasonal', 'pr.sector', 'pr.series', 'pr.txt']\n",
      "['pr.footnote', 'pr.measure', 'pr.period', 'pr.seasonal', 'pr.sector', 'pr.series', 'pr.txt']\n",
      "['pr.measure', 'pr.period', 'pr.seasonal', 'pr.sector', 'pr.series', 'pr.txt']\n",
      "['pr.period', 'pr.seasonal', 'pr.sector', 'pr.series', 'pr.txt']\n",
      "['pr.seasonal', 'pr.sector', 'pr.series', 'pr.txt']\n",
      "['pr.sector', 'pr.series', 'pr.txt']\n",
      "['pr.series', 'pr.txt']\n",
      "['pr.txt']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Request the data source and parse it\n",
    "r = requests.get(BLS_DATA,headers=headers)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "print(soup)\n",
    "\n",
    "for link in soup.find_all(\"a\"):\n",
    "    # Download the current file\n",
    "    file_name = link.get_text()\n",
    "    if file_name == \"[To Parent Directory]\":\n",
    "        continue\n",
    "    file_dl = requests.get(BLS_DATA + file_name)\n",
    "    # If the file doesn't exist in S3, upload it\n",
    "    if file_name not in bucket_objects:\n",
    "        bucket.put_object(Key=file_name, Body=file_dl.content)\n",
    "    # If the file exists in S3\n",
    "    elif file_name in bucket_objects:\n",
    "        # Get the S3 file\n",
    "        s3_response = bucket.Object(file_name).get()\n",
    "        s3_file_content = s3_response['Body'].read()\n",
    "        # If the S3 file is different from the website file, update the S3 file\n",
    "        if file_dl.content != s3_file_content:\n",
    "            bucket.put_object(Key=file_name, Body=file_dl.content)\n",
    "        # Remove the file from the deleted list\n",
    "        deleted_list.remove(file_name)\n",
    "        print(deleted_list)\n",
    "        \n",
    "# Remove files from S3 that are no longer on the website\n",
    "#for file in deleted_list:\n",
    "#   if file != \"population.json\":\n",
    "#        bucket.Object(file).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17b23e06-f37d-4e60-8c66-0239d472f5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head><title>download.bls.gov - /pub/time.series/pr/</title></head><body><h1>download.bls.gov - /pub/time.series/pr/</h1><hr/>\n",
      "<pre><a href=\"/pub/time.series/\">[To Parent Directory]</a><br/><br/>  9/4/2025  8:30 AM          102 <a href=\"/pub/time.series/pr/pr.class\">pr.class</a><br/> 9/13/2022  4:52 PM          562 <a href=\"/pub/time.series/pr/pr.contacts\">pr.contacts</a><br/>  9/4/2025  8:30 AM      1564284 <a href=\"/pub/time.series/pr/pr.data.0.Current\">pr.data.0.Current</a><br/>  9/4/2025  8:30 AM      3187878 <a href=\"/pub/time.series/pr/pr.data.1.AllData\">pr.data.1.AllData</a><br/>  9/4/2025  8:30 AM          176 <a href=\"/pub/time.series/pr/pr.duration\">pr.duration</a><br/>  9/4/2025  8:30 AM           40 <a href=\"/pub/time.series/pr/pr.footnote\">pr.footnote</a><br/>  9/4/2025  8:30 AM          745 <a href=\"/pub/time.series/pr/pr.measure\">pr.measure</a><br/>  1/7/1994  3:53 PM          146 <a href=\"/pub/time.series/pr/pr.period\">pr.period</a><br/>11/18/2011  4:05 PM           79 <a href=\"/pub/time.series/pr/pr.seasonal\">pr.seasonal</a><br/>  9/4/2025  8:30 AM          263 <a href=\"/pub/time.series/pr/pr.sector\">pr.sector</a><br/>  9/4/2025  8:30 AM        15657 <a href=\"/pub/time.series/pr/pr.series\">pr.series</a><br/>11/17/2011  5:11 PM        18343 <a href=\"/pub/time.series/pr/pr.txt\">pr.txt</a><br/></pre><hr/></body></html>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m     bucket.put_object(Key=file_name, Body=file_dl.content)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Remove the file from the deleted list\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mdeleted_list\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(deleted_list)\n",
      "\u001b[31mValueError\u001b[39m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "# Request the data source and parse it\n",
    "import boto3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "AWS_S3_NAME = \"rearc-dataquest-s3bucket\"\n",
    "DATA_SOURCE = \"https://download.bls.gov/pub/time.series/pr/\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"rearc/1.0 (bhanu.tcs@gmail.com)\"\n",
    "}\n",
    "response = requests.get(DATA_SOURCE, headers=headers)\n",
    "\n",
    "r = requests.get(DATA_SOURCE,headers=headers)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "print(soup)\n",
    "\n",
    "for link in soup.find_all(\"a\"):\n",
    "    # Download the current file\n",
    "    file_name = link.get_text()\n",
    "    if file_name == \"[To Parent Directory]\":\n",
    "        continue\n",
    "    file_dl = requests.get(DATA_SOURCE + file_name)\n",
    "    # If the file doesn't exist in S3, upload it\n",
    "    if file_name not in bucket_objects:\n",
    "        bucket.put_object(Key=file_name, Body=file_dl.content)\n",
    "    # If the file exists in S3\n",
    "    elif file_name in bucket_objects:\n",
    "        # Get the S3 file\n",
    "        s3_response = bucket.Object(file_name).get()\n",
    "        s3_file_content = s3_response['Body'].read()\n",
    "        # If the S3 file is different from the website file, update the S3 file\n",
    "        if file_dl.content != s3_file_content:\n",
    "            bucket.put_object(Key=file_name, Body=file_dl.content)\n",
    "        # Remove the file from the deleted list\n",
    "        deleted_list.remove(file_name)\n",
    "        print(deleted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79dba4-2037-43cc-b554-c26a9d891aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
